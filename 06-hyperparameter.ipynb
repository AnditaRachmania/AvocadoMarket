{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_csv/binned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>type</th>\n",
       "      <th>city</th>\n",
       "      <th>average_price</th>\n",
       "      <th>category_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>January</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.22</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>January</td>\n",
       "      <td>organic</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.79</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>January</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>1.00</td>\n",
       "      <td>wholesale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>January</td>\n",
       "      <td>organic</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>1.76</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>January</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Baltimore/Washington</td>\n",
       "      <td>1.08</td>\n",
       "      <td>wholesale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    month          type                  city  average_price  \\\n",
       "0  2015  January  conventional                Albany           1.22   \n",
       "1  2015  January       organic                Albany           1.79   \n",
       "2  2015  January  conventional               Atlanta           1.00   \n",
       "3  2015  January       organic               Atlanta           1.76   \n",
       "4  2015  January  conventional  Baltimore/Washington           1.08   \n",
       "\n",
       "  category_vol  \n",
       "0       medium  \n",
       "1        small  \n",
       "2    wholesale  \n",
       "3        small  \n",
       "4    wholesale  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['average_price'])\n",
    "y = df['average_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'year', 'month', 'city', 'category_vol'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyperparameter LinearRegression dengan Polynomial preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ColumnTransformer([\n",
    "    (\"encode\", OneHotEncoder(), ['type', 'city', 'month', 'category_vol'])\n",
    "], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = Pipeline([\n",
    "    (\"transform\", transform),\n",
    "    (\"poly\", PolynomialFeatures())\n",
    "])\n",
    "\n",
    "lin_poly = Pipeline([\n",
    "    (\"prep_poly\", poly),\n",
    "    (\"algo\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('prep_poly', Pipeline(steps=[('transform',\n",
       "                    ColumnTransformer(remainder='passthrough',\n",
       "                                      transformers=[('encode', OneHotEncoder(),\n",
       "                                                     ['type', 'city', 'month',\n",
       "                                                      'category_vol'])])),\n",
       "                   ('poly', PolynomialFeatures())])),\n",
       "  ('algo', LinearRegression())],\n",
       " 'verbose': False,\n",
       " 'prep_poly': Pipeline(steps=[('transform',\n",
       "                  ColumnTransformer(remainder='passthrough',\n",
       "                                    transformers=[('encode', OneHotEncoder(),\n",
       "                                                   ['type', 'city', 'month',\n",
       "                                                    'category_vol'])])),\n",
       "                 ('poly', PolynomialFeatures())]),\n",
       " 'algo': LinearRegression(),\n",
       " 'prep_poly__memory': None,\n",
       " 'prep_poly__steps': [('transform',\n",
       "   ColumnTransformer(remainder='passthrough',\n",
       "                     transformers=[('encode', OneHotEncoder(),\n",
       "                                    ['type', 'city', 'month', 'category_vol'])])),\n",
       "  ('poly', PolynomialFeatures())],\n",
       " 'prep_poly__verbose': False,\n",
       " 'prep_poly__transform': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('encode', OneHotEncoder(),\n",
       "                                  ['type', 'city', 'month', 'category_vol'])]),\n",
       " 'prep_poly__poly': PolynomialFeatures(),\n",
       " 'prep_poly__transform__n_jobs': None,\n",
       " 'prep_poly__transform__remainder': 'passthrough',\n",
       " 'prep_poly__transform__sparse_threshold': 0.3,\n",
       " 'prep_poly__transform__transformer_weights': None,\n",
       " 'prep_poly__transform__transformers': [('encode',\n",
       "   OneHotEncoder(),\n",
       "   ['type', 'city', 'month', 'category_vol'])],\n",
       " 'prep_poly__transform__verbose': False,\n",
       " 'prep_poly__transform__encode': OneHotEncoder(),\n",
       " 'prep_poly__transform__encode__categories': 'auto',\n",
       " 'prep_poly__transform__encode__drop': None,\n",
       " 'prep_poly__transform__encode__dtype': numpy.float64,\n",
       " 'prep_poly__transform__encode__handle_unknown': 'error',\n",
       " 'prep_poly__transform__encode__sparse': True,\n",
       " 'prep_poly__poly__degree': 2,\n",
       " 'prep_poly__poly__include_bias': True,\n",
       " 'prep_poly__poly__interaction_only': False,\n",
       " 'prep_poly__poly__order': 'C',\n",
       " 'algo__copy_X': True,\n",
       " 'algo__fit_intercept': True,\n",
       " 'algo__n_jobs': None,\n",
       " 'algo__normalize': False}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_poly.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_poly = {\n",
    "    'prep_poly__poly__degree': [2, 3],\n",
    "    \"prep_poly__poly__include_bias\" : ['True', 'False']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_gs = GridSearchCV(lin_poly, param_poly, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:   17.0s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   17.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('prep_poly',\n",
       "                                        Pipeline(steps=[('transform',\n",
       "                                                         ColumnTransformer(remainder='passthrough',\n",
       "                                                                           transformers=[('encode',\n",
       "                                                                                          OneHotEncoder(),\n",
       "                                                                                          ['type',\n",
       "                                                                                           'city',\n",
       "                                                                                           'month',\n",
       "                                                                                           'category_vol'])])),\n",
       "                                                        ('poly',\n",
       "                                                         PolynomialFeatures())])),\n",
       "                                       ('algo', LinearRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'prep_poly__poly__degree': [2, 3],\n",
       "                         'prep_poly__poly__include_bias': ['True', 'False']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prep_poly__poly__degree': 2, 'prep_poly__poly__include_bias': 'True'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Pipeline([\n",
    "    (\"transform\", transform),\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias='True'))\n",
    "])\n",
    "\n",
    "model_poly = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"algo\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 Pipeline(steps=[('transform',\n",
       "                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                    transformers=[('encode',\n",
       "                                                                   OneHotEncoder(),\n",
       "                                                                   ['type',\n",
       "                                                                    'city',\n",
       "                                                                    'month',\n",
       "                                                                    'category_vol'])])),\n",
       "                                 ('poly',\n",
       "                                  PolynomialFeatures(include_bias='True'))])),\n",
       "                ('algo', LinearRegression())])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predPoly = model_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6536250250867395"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_predPoly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- numerical features\n",
    "    karena hanya 1 parameter numerik di variabel X - 'year', maka tidak perlu dilakukan preprocessing untuk variabel numerik\n",
    "- categorical features: OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18679 entries, 14976 to 26606\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   type          18679 non-null  object\n",
      " 1   year          18679 non-null  int64 \n",
      " 2   month         18679 non-null  object\n",
      " 3   city          18679 non-null  object\n",
      " 4   category_vol  18679 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 875.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hype_DT = Pipeline([\n",
    "    (\"encode\", transform),\n",
    "    (\"algo\", DecisionTreeRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('encode',\n",
       "   ColumnTransformer(remainder='passthrough',\n",
       "                     transformers=[('encode', OneHotEncoder(),\n",
       "                                    ['type', 'city', 'month', 'category_vol'])])),\n",
       "  ('algo', DecisionTreeRegressor())],\n",
       " 'verbose': False,\n",
       " 'encode': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('encode', OneHotEncoder(),\n",
       "                                  ['type', 'city', 'month', 'category_vol'])]),\n",
       " 'algo': DecisionTreeRegressor(),\n",
       " 'encode__n_jobs': None,\n",
       " 'encode__remainder': 'passthrough',\n",
       " 'encode__sparse_threshold': 0.3,\n",
       " 'encode__transformer_weights': None,\n",
       " 'encode__transformers': [('encode',\n",
       "   OneHotEncoder(),\n",
       "   ['type', 'city', 'month', 'category_vol'])],\n",
       " 'encode__verbose': False,\n",
       " 'encode__encode': OneHotEncoder(),\n",
       " 'encode__encode__categories': 'auto',\n",
       " 'encode__encode__drop': None,\n",
       " 'encode__encode__dtype': numpy.float64,\n",
       " 'encode__encode__handle_unknown': 'error',\n",
       " 'encode__encode__sparse': True,\n",
       " 'algo__ccp_alpha': 0.0,\n",
       " 'algo__criterion': 'mse',\n",
       " 'algo__max_depth': None,\n",
       " 'algo__max_features': None,\n",
       " 'algo__max_leaf_nodes': None,\n",
       " 'algo__min_impurity_decrease': 0.0,\n",
       " 'algo__min_impurity_split': None,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__min_samples_split': 2,\n",
       " 'algo__min_weight_fraction_leaf': 0.0,\n",
       " 'algo__presort': 'deprecated',\n",
       " 'algo__random_state': None,\n",
       " 'algo__splitter': 'best'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hype_DT.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_DT = {\n",
    "    'algo__max_depth': [None, 3, 5, 7],\n",
    "    'algo__min_samples_leaf': range(1, 10, 2),\n",
    "    'algo__min_samples_split': range(2, 20, 2),\n",
    "    'algo__max_features': [None, 'log2', 'sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_GS = GridSearchCV(hype_DT, param_DT, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('encode',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('encode',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['type',\n",
       "                                                                          'city',\n",
       "                                                                          'month',\n",
       "                                                                          'category_vol'])])),\n",
       "                                       ('algo', DecisionTreeRegressor())]),\n",
       "             param_grid={'algo__max_depth': [None, 3, 5, 7],\n",
       "                         'algo__max_features': [None, 'log2', 'sqrt'],\n",
       "                         'algo__min_samples_leaf': range(1, 10, 2),\n",
       "                         'algo__min_samples_split': range(2, 20, 2)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__max_depth': None,\n",
       " 'algo__max_features': None,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__min_samples_split': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DT = Pipeline([\n",
    "    (\"encode\", transform),\n",
    "    (\"algo\", DecisionTreeRegressor(max_depth=None, max_features=None, min_samples_leaf= 1, min_samples_split= 2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('encode',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('encode', OneHotEncoder(),\n",
       "                                                  ['type', 'city', 'month',\n",
       "                                                   'category_vol'])])),\n",
       "                ('algo', DecisionTreeRegressor())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predDT = model_DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816091509366985"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_predDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter dengan RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressorPolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hype_RF = Pipeline([\n",
    "    (\"encode\", transform),\n",
    "    (\"algo\", RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('encode',\n",
       "   ColumnTransformer(remainder='passthrough',\n",
       "                     transformers=[('encode', OneHotEncoder(),\n",
       "                                    ['type', 'city', 'month', 'category_vol'])])),\n",
       "  ('algo', RandomForestRegressor())],\n",
       " 'verbose': False,\n",
       " 'encode': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('encode', OneHotEncoder(),\n",
       "                                  ['type', 'city', 'month', 'category_vol'])]),\n",
       " 'algo': RandomForestRegressor(),\n",
       " 'encode__n_jobs': None,\n",
       " 'encode__remainder': 'passthrough',\n",
       " 'encode__sparse_threshold': 0.3,\n",
       " 'encode__transformer_weights': None,\n",
       " 'encode__transformers': [('encode',\n",
       "   OneHotEncoder(),\n",
       "   ['type', 'city', 'month', 'category_vol'])],\n",
       " 'encode__verbose': False,\n",
       " 'encode__encode': OneHotEncoder(),\n",
       " 'encode__encode__categories': 'auto',\n",
       " 'encode__encode__drop': None,\n",
       " 'encode__encode__dtype': numpy.float64,\n",
       " 'encode__encode__handle_unknown': 'error',\n",
       " 'encode__encode__sparse': True,\n",
       " 'algo__bootstrap': True,\n",
       " 'algo__ccp_alpha': 0.0,\n",
       " 'algo__criterion': 'mse',\n",
       " 'algo__max_depth': None,\n",
       " 'algo__max_features': 'auto',\n",
       " 'algo__max_leaf_nodes': None,\n",
       " 'algo__max_samples': None,\n",
       " 'algo__min_impurity_decrease': 0.0,\n",
       " 'algo__min_impurity_split': None,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__min_samples_split': 2,\n",
       " 'algo__min_weight_fraction_leaf': 0.0,\n",
       " 'algo__n_estimators': 100,\n",
       " 'algo__n_jobs': None,\n",
       " 'algo__oob_score': False,\n",
       " 'algo__random_state': None,\n",
       " 'algo__verbose': 0,\n",
       " 'algo__warm_start': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hype_RF.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_RF = {\n",
    "    'algo__n_estimators': range(100, 200, 50),\n",
    "    'algo__max_depth': [None, 3, 5, 7],\n",
    "    'algo__min_samples_leaf': range(1, 10, 2),\n",
    "    'algo__min_samples_split': range(2, 20, 4),\n",
    "    'algo__max_features': [None, 'sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_gs = GridSearchCV(hype_RF, params_RF, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 16.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('encode',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('encode',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['type',\n",
       "                                                                          'city',\n",
       "                                                                          'month',\n",
       "                                                                          'category_vol'])])),\n",
       "                                       ('algo', RandomForestRegressor())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'algo__max_depth': [None, 3, 5, 7],\n",
       "                         'algo__max_features': [None, 'sqrt'],\n",
       "                         'algo__min_samples_leaf': range(1, 10, 2),\n",
       "                         'algo__min_samples_split': range(2, 20, 4),\n",
       "                         'algo__n_estimators': range(100, 200, 50)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__max_depth': None,\n",
       " 'algo__max_features': None,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__min_samples_split': 2,\n",
       " 'algo__n_estimators': 150}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF = Pipeline([\n",
    "    (\"encode\", transform),\n",
    "    (\"algo\", RandomForestRegressor(max_depth=None, max_features=None, min_samples_leaf= 1, min_samples_split= 2, n_estimators=150))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('encode',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('encode', OneHotEncoder(),\n",
       "                                                  ['type', 'city', 'month',\n",
       "                                                   'category_vol'])])),\n",
       "                ('algo',\n",
       "                 RandomForestRegressor(max_features=None, n_estimators=150))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predRF = model_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348297843992323"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_predRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['model'] = ['Polynomial Regression', 'Decision Tree', 'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['MAE'] = [mean_absolute_error(y_test, y_predPoly), mean_absolute_error(y_test, y_predDT), mean_absolute_error(y_test, y_predRF)]\n",
    "summary['MSE'] = [mean_squared_error(y_test, y_predPoly), mean_squared_error(y_test, y_predDT), mean_squared_error(y_test, y_predRF)]\n",
    "summary['RMSE'] = [np.sqrt(mean_squared_error(y_test, y_predPoly)), np.sqrt(mean_squared_error(y_test, y_predDT)), np.sqrt(mean_squared_error(y_test, y_predRF))]\n",
    "summary['r2_score'] = [r2_score(y_test, y_predPoly), r2_score(y_test, y_predDT), r2_score(y_test, y_predRF)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>0.171990</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>0.228133</td>\n",
       "      <td>0.653625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.027633</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>0.816092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.108070</td>\n",
       "      <td>0.024818</td>\n",
       "      <td>0.157537</td>\n",
       "      <td>0.834830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model       MAE       MSE      RMSE  r2_score\n",
       "0  Polynomial Regression  0.171990  0.052045  0.228133  0.653625\n",
       "1          Decision Tree  0.111627  0.027633  0.166233  0.816092\n",
       "2          Random Forest  0.108070  0.024818  0.157537  0.834830"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Model dengan r2_score paling baik adalah Random Forest dengan parameter-parameter sbb:\n",
    "- 'algo__max_depth': None,\n",
    "- 'algo__max_features': None,\n",
    "- 'algo__min_samples_leaf': 1,\n",
    "- 'algo__min_samples_split': 2,\n",
    "- 'algo__n_estimators': 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
